1.需要使用数据库,结构化存储 FAQ 类目,将历史 FAQ 通过 Sentence-BERT 进行转化为句向量,然后存入到数据库表里面,避免每次用户提问时重复计算

2.使用句子嵌入模型, bge-small-zh-v1.5    属于 SBERT 类架构,为中文句子语义表示优化，在问答匹配、检索等任务上表现优异,这一步不使用大语言模型,是因为大语言模型 推理成本高、响应慢，不擅长精准相似匹配

3.原始 BERT 并不适合直接用于句子相似度检索任务,使用SBERT, SBERT 将每个句子编码为numpy数组,：语义越接近，向量越相似。精准找到历史中最接近的答案

4.如果只是单纯针对此任务,那么可以完全不使用大语言模型,我们只需要完善faq数据即可,如果业务要求,句句回应相关信息,那么就可以设置业务流程,如果没有找到对应的faq回答,那么走大语言模型,同时外挂知识库,然后去做回答



